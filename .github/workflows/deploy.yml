name: deploy

on:
  # Manual run
  workflow_dispatch:

  # Auto run when relevant files change on main
  push:
    branches: [ main ]
    paths:
      # generated inputs and outputs
      - "data/**"
      - "refined_policies/**"
      # your pipeline code / scripts
      - "script/**"
      - "run_all.py"
      - "fix_policy_summary.py"
      - "fetch_iam_policies.py"
      - "tests/**"
      # allow editing this workflow to trigger a test run too
      - ".github/workflows/deploy.yml"

jobs:
  deploy:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      id-token: write  # harmless if you later switch to OIDC
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install deps (best effort)
        run: |
          set -e
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          fi

      # (Optional) run your full pipeline if it exists
      - name: (Optional) Run pipeline
        run: |
          set -e
          if [ -f script/run_all.py ]; then
            python script/run_all.py
          else
            echo "No script/run_all.py found; skipping."
          fi

      # Build the final combined CSV the dashboard expects.
      # - If your pipeline already produced combined_policy_summary.csv, we keep it.
      # - Otherwise we merge any policy_usage_report_*.csv files into that name.
      - name: Compose combined CSV from per-policy files
        run: |
          set -euo pipefail
          FINAL=combined_policy_summary.csv

          if [ -f "$FINAL" ]; then
            echo "::notice title=CSV::Found $FINAL already, keeping as-is."
            exit 0
          fi

          shopt -s nullglob
          files=( policy_usage_report_*.csv data/policy_usage_report_*.csv )

          if [ ${#files[@]} -eq 0 ]; then
            echo "No per-policy CSVs found. Listing repo for debugging:"
            ls -la
            echo "::error::Could not find $FINAL nor policy_usage_report_*.csv to combine."
            exit 1
          fi

          echo "Merging ${#files[@]} files into $FINAL â€¦"
          # Keep header from the first file only
          awk 'FNR==1 && NR!=1 {next} {print}' "${files[@]}" > "$FINAL"

          echo "Result:"
          wc -l "$FINAL"
          head -n 5 "$FINAL" || true

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id:     ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region:            ${{ secrets.AWS_REGION }}

      - name: Upload combined CSV to S3
        run: |
          set -e
          aws s3 cp combined_policy_summary.csv \
            "s3://${{ secrets.S3_BUCKET }}/combined_policy_summary.csv" \
            --acl private

      - name: Refresh QuickSight dataset
        run: |
          set -e
          ING="ing-$(date +%s)"
          echo "Triggering QuickSight create-ingestion: $ING"
          aws quicksight create-ingestion \
            --aws-account-id  "${{ secrets.AWS_ACCOUNT_ID }}" \
            --data-set-id     "${{ secrets.QS_DATASET_ID }}" \
            --ingestion-id    "$ING" \
            --region          "${{ secrets.AWS_REGION }}"
          echo "Ingestion submitted."
