name: deploy

on:
  workflow_dispatch:        # allow manual runs
  push:
    branches: [ main ]
    paths:
      - "data/**/*.csv"
      - "script/**"
      - ".github/workflows/deploy.yml"

jobs:
  deploy:
    runs-on: ubuntu-latest
    permissions:
      id-token: write
      contents: read

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          # If pandas is NOT in your requirements.txt, uncomment this:
          # pip install pandas

      # (optional) Rebuild your outputs if the pipeline generates the per-policy CSVs
      - name: (Optional) Run pipeline
        run: |
          python script/run_all.py || true

      # 👉 Add this step
      - name: Compose combined CSV from per-policy files
        run: |
          python - <<'PY'
          import pandas as pd, glob, os, sys
          files = sorted(glob.glob("**/policy_usage_report_*.csv", recursive=True))
          if not files:
              print("❌ No per-policy files found. Repo layout is:")
              os.system("ls -lR")
              sys.exit(1)
          dfs = []
          for f in files:
              try:
                  df = pd.read_csv(f)
                  dfs.append(df)
                  print(f"✅ loaded {f} ({len(df)} rows)")
              except Exception as e:
                  print(f"⚠️  skipping {f}: {e}")
          if not dfs:
              print("❌ Found files but none could be read as CSV.")
              sys.exit(1)
          out = "combined_policy_summary.csv"
          pd.concat(dfs, ignore_index=True).to_csv(out, index=False)
          print(f"🎉 wrote {out} from {len(dfs)} files: {files}")
          PY

      # Use your existing access-key secrets (fine for now)
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id:     ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region:            ${{ secrets.AWS_REGION }}

      - name: Who am I?
        run: aws sts get-caller-identity

      - name: Upload combined CSV to S3
        run: |
          aws s3 cp combined_policy_summary.csv \
            s3://${{ secrets.S3_BUCKET }}/combined_policy_summary.csv \
            --acl private

      - name: Refresh QuickSight dataset
        run: |
          aws quicksight create-ingestion \
            --aws-account-id  ${{ secrets.AWS_ACCOUNT_ID }} \
            --data-set-id     ${{ secrets.QS_DATASET_ID }} \
            --ingestion-id    "ing-$(date +%s)" \
            --region          ${{ secrets.AWS_REGION }}