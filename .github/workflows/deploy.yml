name: deploy

on:
  workflow_dispatch:
  push:
    branches: [ main ]
    paths:
      - "script/**"
      - "data/**"
      - ".github/workflows/deploy.yml"

jobs:
  deploy:
    runs-on: ubuntu-latest
    permissions:
      contents: read

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps & rebuild outputs
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          python script/run_all.py || true
          echo "=== Repo tree (top) ==="
          ls -la
          echo "=== data/ ==="
          ls -la data || true
          echo "=== refined_policies/ ==="
          ls -la refined_policies || true

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id:     ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region:            ${{ secrets.AWS_REGION }}

      - name: Who am I?
        run: aws sts get-caller-identity

      # Upload combined CSV (adjust path if your file lives elsewhere)
      - name: Upload combined CSV to S3
        run: |
          # Use whatever you actually produce; change if needed.
          # If your pipeline produces `data/policy_summary.csv`, switch the source path below.
          SRC="data/policy_summary.csv"
          if [ ! -f "$SRC" ]; then
            echo "File $SRC not found, trying data/policy_usage_report.csv"
            SRC="data/policy_usage_report.csv"
          fi
          if [ ! -f "$SRC" ]; then
            echo "File $SRC not found, trying combined_policy_summary.csv at repo root"
            SRC="combined_policy_summary.csv"
          fi
          if [ ! -f "$SRC" ]; then
            echo "No known CSV found. Listing data/:"
            ls -la data || true
            echo "::error::No combined CSV found to upload."
            exit 1
          fi
          echo "Uploading $SRC -> s3://${{ secrets.S3_BUCKET }}/combined_policy_summary.csv"
          aws s3 cp "$SRC" "s3://${{ secrets.S3_BUCKET }}/combined_policy_summary.csv" --acl private

      - name: Refresh QuickSight dataset
        env:
          AWS_ACCOUNT_ID: ${{ secrets.AWS_ACCOUNT_ID }}
          QS_DATASET_ID:  ${{ secrets.QS_DATASET_ID }}
          AWS_REGION:     ${{ secrets.AWS_REGION }}
        run: |
          echo "Creating QuickSight ingestion for dataset $QS_DATASET_ID in $AWS_ACCOUNT_ID ($AWS_REGION)"
          aws quicksight create-ingestion \
            --aws-account-id  "$AWS_ACCOUNT_ID" \
            --data-set-id     "$QS_DATASET_ID" \
            --ingestion-id    "ing-$(date +%s)" \
            --region          "$AWS_REGION"
